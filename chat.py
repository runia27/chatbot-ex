import os

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone


st.set_page_config(page_title='ì „ì„¸ì‚¬ê¸°í”¼í•´ ìƒë‹´ ì±—ë´‡', page_icon='ğŸ¤–')

st.title('ì „ì„¸ì‚¬ê¸°í”¼í•´ ìƒë‹´ ì±—ë´‡ ğŸ¤–')


if 'message_list' not in st.session_state:
    st.session_state.message_list = []

print(f"before: {st.session_state.message_list}")

## ì´ì „ ì±„íŒ… í™”ë©´ ì¶œë ¥
for i in st.session_state.message_list:
    with st.chat_message(i['role']):
        st.write(i['content'])


## AI ë©”ì„¸ì§€ í•¨ìˆ˜ ì •ì˜ 
def get_aimessage(user_message):

    load_dotenv()
    api_key = os.getenv('PINECONE_API_KEY')
    LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')

    pc = Pinecone(api_key=api_key)

    ## ì„ë² ë”©
    embedding = OpenAIEmbeddings(
        model="text-embedding-3-large",
    )

    # íŒŒì¸ì½˜ì— ì €ì¥ 
    
    database = PineconeVectorStore.from_existing_index(
        embedding=embedding,
        index_name='law1and2-quiz4'
    )

    llm = ChatOpenAI()

    prompt = hub.pull("rlm/rag-prompt")

    ## RetrievalQA êµ¬í˜„
    def format_docs(docs):
        return '\n\n'.join(doc.page_content for doc in docs)

    chain_lcel = (
        {
            "context" : database.as_retriever() | format_docs,
            "question" : RunnablePassthrough(),
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    aimessage = chain_lcel.invoke(user_message)
    return aimessage

## í”„ë¡¬í”„íŠ¸ì°½(ì±„íŒ…ì°½) êµ¬í˜„
if inputchat := st.chat_input(placeholder="ì „ì„¸ì‚¬ê¸° í”¼í•´ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”."):
    with st.chat_message("user"):    
        st.write(f"{inputchat}")
    st.session_state.message_list.append({'role': 'user', 'content': inputchat})
    
    aimessage = get_aimessage(inputchat)
    
    with st.chat_message("ai"):
        st.write(aimessage)
    st.session_state.message_list.append({'role': 'ai', 'content': aimessage})


print(f"after: {st.session_state.message_list}")
import os

from dotenv import load_dotenv
from langchain.chains import (create_history_aware_retriever,
                              create_retrieval_chain)
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.prompts import (ChatPromptTemplate, FewShotPromptTemplate,
                                    MessagesPlaceholder, PromptTemplate)
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

from config import answer_examlples


load_dotenv()

# llm í•¨ìˆ˜ ì •ì˜
def load_llm(model="gpt-4o"):
    llm = ChatOpenAI(model=model)
    return llm


# ë°ì´í„°ë² ì´ìŠ¤ í•¨ìˆ˜ ì •ì˜ 
def load_vectorstore():
    api_key = os.getenv('PINECONE_API_KEY')
    Pinecone(api_key=api_key)

    embedding = OpenAIEmbeddings(
        model="text-embedding-3-large",
    )    
   
    database = PineconeVectorStore.from_existing_index(
        embedding=embedding,
        index_name="law1and2-quiz4",
    )
    return database

# ì„¸ì…˜ ì•„ì´ë”” ìƒì„±
store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


# íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„
def build_history_aware_retriever(llm, retriever):

    question_prompt = ('''
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ì°¸ì¡°í•œë‹¤ë©´, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì„ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì´ ì´ë¯¸ ë…ë¦½ì ì¸ ë¬¸ì¥ì´ë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- ë‹µë³€ì€ í•˜ì§€ ì•Šê³ , ì˜¤ì§ ì§ˆë¬¸ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
- í•­ìƒ ì§ˆë¬¸ í˜•íƒœë¡œ ëë‚˜ì•¼ í•˜ë©°, ë¬¸ì¥ì€ ì •í™•í•˜ê³  ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.

''')

    contextualize_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", question_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )
    history_retriever = create_history_aware_retriever(
        llm, retriever, contextualize_prompt
    )
    return history_retriever


## few shot
def build_few_shot_examples() -> str:

    example_prompt = PromptTemplate.from_template("Question: {input}\n{answer}")

    few_shot_prompt = FewShotPromptTemplate(
        examples=answer_examlples,
        example_prompt=example_prompt,
        prefix= "ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš” : ",
        suffix="Question: {input}",
        input_variables=["input"],
    )
   
    formated_few_shot_prompt = few_shot_prompt.format(input="{input}")
    return formated_few_shot_prompt
    

# 
def build_qa_prompt():
    ## [keyword dictionary]
    # 1. ê¸°ë³¸í˜•íƒœ : í‚¤ í•˜ë‚˜ë‹¹ ì„¤ëª… í•˜ë‚˜, ë‹¨ìˆœí•˜ê³  ë¹ ë¦„
    # ìš©ë„ : FAQ ì±—ë´‡, ë²„íŠ¼ì‹ ì‘ë‹µ
    # 2. ì§ˆë¬¸í˜•íƒœ : ìœ ì‚¬í•œ ì§ˆë¬¸ì— ì—¬ëŸ¬ í‚¤ë¡œ ë¶„ê¸°í•˜ë©° ëª¨ë‘ ê°™ì€ ëŒ€ë‹µìœ¼ë¡œ ì—°ê²°, fallback ëŒ€ì‘
    # ìš©ë„ : ë‹¨ë‹µ ì±—ë´‡, í‚¤ì›Œë“œ FAQ ì±—ë´‡
    # 3. í‚¤ì›Œë“œ _ íƒœê·¸ ê¸°ë°˜

    
    keyword_dictionary = {
#         'ì„ëŒ€ì¸': '''
# ì„ëŒ€ì¸ ë˜ëŠ” ë‹¤ìŒ ê° ëª©ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ìë¥¼ ë§í•œë‹¤.
# ê°€. ì„ëŒ€ì¸ì˜ ëŒ€ë¦¬ì¸, ê·¸ ë°–ì— ì„ëŒ€ì¸ì„ ìœ„í•˜ì—¬ ì£¼íƒì˜ ì„ëŒ€ì— ê´€í•˜ì—¬ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì
# ë‚˜. ì„ëŒ€ì¸ì˜ ì˜ë¢°ë¥¼ ë°›ì€ ê³µì¸ì¤‘ê°œì‚¬(ì¤‘ê°œë³´ì¡°ì¸ì„ í¬í•¨í•œë‹¤)
# ë‹¤. ì„ëŒ€ì¸ì„ ìœ„í•˜ì—¬ ì„ì°¨ì¸ì„ ëª¨ì§‘í•˜ëŠ” ì(ê·¸ í”¼ê³ ìš©ì¸ì„ í¬í•¨í•œë‹¤)
# ë¼. ë‹¤ìˆ˜ ì„ëŒ€ì¸ì˜ ë°°í›„ì— ìˆëŠ” ë™ì¼ì¸
# ë§ˆ. ë¼ëª©ì˜ ë™ì¼ì¸ì´ ì§€ë°°í•˜ê±°ë‚˜ ê²½ì œì  ì´ìµì„ ê³µìœ í•˜ëŠ” ì¡°ì§
# ë°”. ë¼ëª©ì˜ ë™ì¼ì¸ì´ë‚˜ ë§ˆëª©ì˜ ì¡°ì§ì„ ë°°í›„ì— ë‘” ë‹¤ìˆ˜ì˜ ì„ëŒ€ì¸
#     ''',
#         'ì£¼íƒ': '''
# ã€Œì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ã€ ì œ2ì¡°ì— ë”°ë¥¸ ì£¼ê±°ìš© ê±´ë¬¼(ê³µë¶€ìƒ ì£¼ê±°ìš© ê±´ë¬¼ì´ ì•„ë‹ˆë¼ë„ ì„ëŒ€ì°¨ê³„ì•½ ì²´ê²° ë‹¹ì‹œ ì„ëŒ€ì°¨ëª©ì ë¬¼ì˜ êµ¬ì¡°ì™€ ì‹¤ì§ˆì´ ì£¼ê±°ìš© ê±´ë¬¼ì´ê³  ì„ì°¨ì¸ì˜ ì‹¤ì œ ìš©ë„ê°€ ì£¼ê±°ìš©ì¸ ê²½ìš°ë¥¼ í¬í•¨í•œë‹¤)ì„ ë§í•œë‹¤.
#     ''',
#         'ì„ëŒ€ì¸ ì•Œë ¤ì¤˜': '''
# ì„ëŒ€ì¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤:

# ê¸°ë³¸ ì •ì˜:
# ì„ëŒ€ì¸ì€ ì£¼íƒ ë“±ì„ ì†Œìœ í•˜ê³  ì´ë¥¼ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë¹Œë ¤ì£¼ëŠ” ìë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë³´í†µ ì„ì°¨ì¸ìœ¼ë¡œë¶€í„° ì„ëŒ€ë£Œë¥¼ ë°›ê³  ì£¼ê±° ë˜ëŠ” ì‚¬ìš©ì„ í—ˆë½í•©ë‹ˆë‹¤.

# ëŒ€ë¦¬ì¸ ë° ìœ„ì„ì:
# ì„ëŒ€ì¸ì„ ëŒ€ì‹ í•˜ì—¬ ì„ëŒ€ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëŒ€ë¦¬ì¸ë„ ì„ëŒ€ì¸ì˜ ë²”ì£¼ì— í¬í•¨ë©ë‹ˆë‹¤.
# ì„ëŒ€ì¸ì˜ ëŒ€ë¦¬ì¸ì€ ì£¼íƒì˜ ì„ëŒ€ì— ê´€í•œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤.

# ê³µì¸ì¤‘ê°œì‚¬ í¬í•¨:
# ì„ëŒ€ì¸ì˜ ì˜ë¢°ë¥¼ ë°›ì•„ ì„ì°¨ì¸ê³¼ì˜ ê³„ì•½ì„ ì¤‘ê°œí•˜ëŠ” ê³µì¸ì¤‘ê°œì‚¬ë„ ì„ëŒ€ì¸ì˜ ë²”ì£¼ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì„ì°¨ì¸ ëª¨ì§‘ì:
# ì„ëŒ€ì¸ì„ ëŒ€ì‹ í•´ ì„ì°¨ì¸ì„ ëª¨ì§‘í•˜ëŠ” ìë„ í¬í•¨ë©ë‹ˆë‹¤. ì´ëŠ” í”¼ê³ ìš©ì¸ì„ í¬í•¨í•œ ê²½ìš°ë„ í•´ë‹¹ë©ë‹ˆë‹¤.

# ë‹¤ìˆ˜ ì„ëŒ€ì¸ì˜ ë™ì¼ì¸ ë°°í›„ì:
# ì—¬ëŸ¬ ì„ëŒ€ì¸ì„ ë’¤ì—ì„œ ì§€ë°°í•˜ê±°ë‚˜ ê²½ì œì  ì´ìµì„ ê³µìœ í•˜ëŠ” ë™ì¼ì¸ë„ ì„ëŒ€ì¸ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì¡°ì§ ë° ê²½ì œ ê³µìœ :
# ë™ì¼ì¸ì´ ì§€ë°°í•˜ëŠ” ì¡°ì§ ë˜ëŠ” ê²½ì œì  ì´ìµì„ ê³µìœ í•˜ëŠ” ì¡°ì§ì´ í¬í•¨ë˜ë©°, ì´ë“¤ì´ ë°°í›„ì— ìˆëŠ” ë‹¤ìˆ˜ì˜ ì„ëŒ€ì¸ë„ ì„ëŒ€ì¸ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì´ëŸ¬í•œ ë‚´ìš©ì€ íŠ¹ì • ë²•ì  ìƒí™©ì—ì„œ 'ì„ëŒ€ì¸'ì˜ ì •ì˜ê°€ ì–´ë–»ê²Œ í™•ì¥ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. (ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²•)    
#     ''',    
    'ì„ëŒ€ì¸' : {
        'definition': 'ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì œ2ì¡° 2í•­ì—ì„œ ì„ëŒ€ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤',
        'source': 'ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì œ2ì¡°',
        'tags': ['ë²•ë¥ ', 'ìš©ì–´', 'ê¸°ì´ˆ'],
        },
    'ì£¼íƒ' : {
        'definition': 'ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì œ2ì¡° 1í•­ì—ì„œ ì£¼íƒì„ ì •ì˜í•©ë‹ˆë‹¤',
        'source': 'ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì œ2ì¡°',
        'tags': ['ë²•ë¥ ', 'ìš©ì–´', 'ê¸°ì´ˆ'],
        },
    }

    dictionary_text = '\n'.join([
        f"{k} ({', '.join(v['tags'])}): {v['definition']} [ì¶œì²˜: {v['source']}])" 
        for k, v in keyword_dictionary.items()
    ])

    prompt = ('''
[Identity]
- ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
- "context"ì™€ "keyward_dictionary"ë¥¼ ì°¸ê³ í•´ ì§ˆë¬¸ì— ëŒ€í•´ ì¼ëª©ìš”ì—°í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. 
- í•­ëª©ë³„ë¡œ í‘œì‹œí•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
- ë‹µë³€ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ëŠ” ê´€ë ¨ ë²•ì¡°í•­ì„ ì†Œê´„í˜¸ ì•ˆì— ë„£ì–´ ê°™ì´ ëª…ì‹œí•´ì£¼ì„¸ìš”. 
- ì–´ë–¤ ê²ƒì— ëŒ€í•´ ì•Œë ¤ë‹¬ë¼ëŠ” ì§ˆë¬¸ì€ ì–´ë–¤ ê²ƒì— ëŒ€í•´ ì„¤ëª…í•´ë‹¬ë¼ëŠ” ë§ê³¼ ê°™ìŠµë‹ˆë‹¤. 
- ì‚¬ìš©ìë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
- ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì—ëŠ” ì „ì„¸ì‚¬ê¸°ì™€ ê´€ë ¨ëœ ë¹„ìŠ·í•œ ì§ˆë¬¸ì„ ë¬¼ì–´ë³¸ê²Œ ë§ëŠ”ì§€ ë˜ë¬»ìŠµë‹ˆë‹¤.

context: {context}       
question: {input}    
keyword_dictionary: {dictionary_text}                               
answer:
    ''')

    formated_few_shot_prompt = build_few_shot_examples()

    qa_prompt = ChatPromptTemplate.from_messages([
    ("system", prompt),
    ("assistant", formated_few_shot_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
    ]).partial(dictionary_text=dictionary_text)
    
    return qa_prompt


# RetrievalQA í•¨ìˆ˜ ì •ì˜
def get_all_chain():

    database = load_vectorstore()
    retriever = database.as_retriever(search_kwargs={'k': 2})
    llm = load_llm()

    history_retriever = build_history_aware_retriever(llm, retriever)
    qa_prompt = build_qa_prompt()
    
    answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(history_retriever, answer_chain)

    all_chain = RunnableWithMessageHistory(
        rag_chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
        output_messages_key="answer"
    ).pick("answer")

    return all_chain


## AI ë©”ì„¸ì§€ í•¨ìˆ˜ ì •ì˜ 
def stream_get_aimessage(user_message, session_id='default'):        
    all_chain = get_all_chain()

    aimessage = all_chain.stream(
        {"input": user_message},
        config={"configurable":{"session_id": session_id}},
    )

    print(f"ëŒ€í™”ì´ë ¥: {get_session_history(session_id).messages} \nğŸ¾\n")
    print('=' * 50)
    print(f"{session_id}")

    retriever = load_vectorstore().as_retriever(search_kwargs={'k': 2})
    search_result = retriever.invoke(user_message)
    print(f"\nê²€ìƒ‰ê²°ê³¼ : \n{search_result}")

    return aimessage

